{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "random_action_wrapper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "da9Gy4HUozuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym \n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlLXLEsMpXDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomActionWrapper(gym.ActionWrapper):\n",
        "  def __init__(self, env, epsilon = 0.1):\n",
        "    super(RandomActionWrapper, self).__init__(env)\n",
        "    self.epsilon = epsilon   # epsilon is probability of a random action\n",
        "\n",
        "  def action(self, action):\n",
        "    if random.random() < self.epsilon:\n",
        "      print('Random!')\n",
        "      return self.env.action_space.sample()\n",
        "    return action"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTqrb7EZqrYe",
        "colab_type": "text"
      },
      "source": [
        "This is a method that we need to override from a parent's class to tweak the\n",
        "agent's actions. Every time we roll the die and with the probability of epsilon, we\n",
        "sample a random action from the action space and return it instead of the action\n",
        "the agent has sent to us. Note that using action_space and wrapper abstractions,\n",
        "we were able to write abstract code, which will work with any environment from\n",
        "the Gym."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIvuvN1KqdDd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = RandomActionWrapper(gym.make('CartPole-v0'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xLdwzjTrIHE",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to apply our wrapper. We will create a normal CartPole\n",
        "environment and pass it to our wrapper constructor. From here on, we use our\n",
        "wrapper as a normal Env instance, instead of the original CartPole. As the\n",
        "Wrapper class inherits the Env class and exposes the same interface, we can nest\n",
        "our wrappers in any combination we want."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQrH7l5tq7Vt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "697e50db-b846-4bd5-ce87-dd2ac98b8c6f"
      },
      "source": [
        "obs = env.reset()\n",
        "total_reward = 0.0\n",
        "while True:\n",
        "  obs, reward, done, _ = env.step(0)\n",
        "  total_reward += reward\n",
        "  if done:\n",
        "    break\n",
        "print(\"Reward got: %.2f\" % total_reward)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random!\n",
            "Random!\n",
            "Random!\n",
            "Reward got: 13.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnJGyfjCrSjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}