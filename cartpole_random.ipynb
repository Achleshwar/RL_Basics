{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cartpole_random.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bILXNdMignmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gym"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBvGz6yig1-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "e = gym.make('CartPole-v0')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MQofAEniFP1",
        "colab_type": "text"
      },
      "source": [
        "This environment is from the \"classic control\" group and its gist is to\n",
        "control the platform with a stick attached by its bottom part. The trickiness is that this stick tends to fall right or left and you need to\n",
        "balance it by moving the platform to the right or left on every step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wenGX792hPOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "17b7cc75-9e89-4284-fdb7-7187024642c1"
      },
      "source": [
        "obs = e.reset()\n",
        "obs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.033498  , -0.01541619,  0.02484131,  0.03696866])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQQm5-lCiQAd",
        "colab_type": "text"
      },
      "source": [
        "Here we reset the environment and obtain the first observation (we always need\n",
        "to reset the newly created environment).\n",
        "\n",
        "The observation of this environment is four float numbers containing\n",
        "information about the x coordinate of the stick's center of mass, its speed, its\n",
        "angle to the platform, and its angular speed. Of course, by applying some math\n",
        "and physics knowledge, it won't be complicated to convert these numbers into\n",
        "actions when we need to balance the stick, but our problem is much trickier: how\n",
        "do we learn to balance this system without knowing the exact meaning of the\n",
        "observed numbers and only by getting the reward?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnlIPuiIhvf8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b4928a87-cc3d-4cea-c289-2c19f0f9b6c9"
      },
      "source": [
        "#the observation is four numbers, so let's check how we can know this in advance:\n",
        "print(e.action_space)\n",
        "print(e.observation_space)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discrete(2)\n",
            "Box(4,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VkgcGNYiqbF",
        "colab_type": "text"
      },
      "source": [
        "The action_space field is of the Discrete type, so our actions will be just 0 or\n",
        "1, where 0 means pushing the platform to the left and 1 means to the right. The\n",
        "observation space is of Box(4,) which means a vector of size four with values\n",
        "inside the [âˆ’inf, inf] interval."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHMHCCi6h17-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df5f6e39-5c95-45c0-f632-40a58d0dec7f"
      },
      "source": [
        "e.step(0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([-0.03380633, -0.2108854 ,  0.02558068,  0.33738461]), 1.0, False, {})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQbgNU_tjMTN",
        "colab_type": "text"
      },
      "source": [
        "Here we pushed our platform to the left by executing the action 0 and got the\n",
        "tuple of four elements:\n",
        "<ul>\n",
        "<li>A new observation that is a new vector of four numbers</li>\n",
        "<li>A reward of 1.0</li>\n",
        "<li>The done flag = False, which means that the episode is not over yet and\n",
        "we're more or less okay</li>\n",
        "<li>Extra information about the environment that is an empty dictionary</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdWehPIyh3us",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "607e3877-a6ec-411c-b54c-6e2a876607fd"
      },
      "source": [
        "e.action_space.sample()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKxsCyyXjz7t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e5d4323-d627-4673-e98d-1228cf9c0e2d"
      },
      "source": [
        "e.action_space.sample()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXjOZyuUj3Uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "910e41b2-da8b-4f10-ecb2-34c5ae9366b0"
      },
      "source": [
        "e.observation_space.sample()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.3731933e+00, -7.2842941e+37,  3.0977464e-01, -5.3017316e+37],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_08-GUZkCuV",
        "colab_type": "text"
      },
      "source": [
        "Here we used the sample() method of the Space class on action_space and\n",
        "observation_space. This method returns a random sample from the underlying\n",
        "space, which in the case of our Discrete action space means a random number\n",
        "of 0 or 1 and for the observation space is a random vector of four numbers. The\n",
        "random sample of the observation space may not look useful, and this is true, but\n",
        "the sample from the action space could be used when we're not sure how to\n",
        "perform an action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO3zqg7ake6l",
        "colab_type": "text"
      },
      "source": [
        "### Enough of playing around with the environment. Now, let's create a random agent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4t-zaV5j6F2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env = gym.make('CartPole-v0')\n",
        "total_reward = 0.0\n",
        "total_steps = 0\n",
        "obs = env.reset()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEzJ3CaLmElu",
        "colab_type": "text"
      },
      "source": [
        "Here, we create the environment and initialize the counter of steps and the\n",
        "reward accumulator. On the last line, we reset the environment to obtain the first\n",
        "observation (which we'll not use, as our agent is stochastic)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NoujeyY0k8jX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6bb92112-be75-480f-cebd-cce2ba562b61"
      },
      "source": [
        "while True:\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, _ = env.step(action)\n",
        "  total_reward += reward\n",
        "  total_steps += 1\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "print('Episode done in {} steps. \\n Total reward : {}'.format(total_steps, total_reward))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Episode done in 32 steps. \n",
            " Total reward : 32.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymZ_atmvmRLl",
        "colab_type": "text"
      },
      "source": [
        "In this loop, we sample a random action, then ask the environment to execute it\n",
        "and return to us the next observation(obs), the reward, and the done flag. If the\n",
        "episode is over, we stop the loop and show how many steps we've done and how\n",
        "much reward has been accumulated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGu168jSlxGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}